{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "re.compile(r'[ .,?!가-힣ㅋㅎㅜㅠa-zA-Z0-9]+')\n",
    "\n",
    "1. 띄어쓰기 해주기\n",
    "2. 중복 글자 처리\n",
    "3. 문장 나누기\n",
    "4. 1단어 제거"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. data fommat 통일\n",
    "2. 각 데이터 전처리 파이프라인 통과\n",
    "3. 각 데이터 train, test 데이터셋 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pykospacing import spacing\n",
    "from soynlp.normalizer import repeat_normalize\n",
    "from kss import kss\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 포멧 통일 작업 #\n",
    "# 추후 전처리 프로세스 통일을 위해 #\n",
    "# 컬럼 2개(text, label) #\n",
    "\n",
    "def data_format_setting_hotel(dataFileName):\n",
    "    data = pd.read_csv(dataFileName)\n",
    "    data.columns = ['text', 'label']\n",
    "    data.drop_duplicates(subset=['text'], inplace=True)\n",
    "    data = data.dropna(axis=0)\n",
    "    data.to_csv('data/origin/hotel.txt', sep = '\\t', index = False)\n",
    "    \n",
    "def data_format_setting_movie(dataFileName):\n",
    "    data = pd.read_table(dataFileName)\n",
    "    data = data.drop(['id'], axis=1)\n",
    "    data.columns = ['text', 'label']\n",
    "    data.drop_duplicates(subset=['text'], inplace=True)\n",
    "    data = data.dropna(axis=0)\n",
    "    data.to_csv('data/origin/movie.txt', sep = '\\t', index = False)\n",
    "    \n",
    "def data_format_setting_shopping(dataFileName):\n",
    "    data = pd.read_table(dataFileName, header=None)\n",
    "    data.columns = ['rating', 'text']\n",
    "    data['label'] = np.select([data.rating > 3], [1], default=0)\n",
    "    data = data.drop(['rating'], axis=1)\n",
    "    data.drop_duplicates(subset=['text'], inplace=True)\n",
    "    data = data.dropna(axis=0)\n",
    "    data.to_csv('data/origin/shopping.txt', sep = '\\t', index = False)\n",
    "\n",
    "data_format_setting_movie('data/origin/ratings_train.txt')\n",
    "data_format_setting_hotel('data/origin/hotel_pos_neg.csv')\n",
    "data_format_setting_shopping('data/origin/naver_shopping.txt')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19fbff1063ba43548bec50f5b93c7912",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b83ce8f861d469d913af27ebf9f8e98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ea3e7573f5b4ecfb6a002026aea32f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b80709fa3d3d4e8d99ed09fb084d3c60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aab3ed0f46e54b1cb688082ac61af828",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5df6c13bddf9457bab59037ceb514b34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "del_filter1 = re.compile(r'[!?,.ㅋㅎㅜㅠ가-힣0-9]+')\n",
    "del_filter2 = re.compile(r'[ㅋㅎㅜㅠ가-힣0-9]+')\n",
    "\n",
    "# label = 텍스트가 있는 컬럼 이름\n",
    "def regex_spacing_normalization(data, label):\n",
    "    for idx, item in tqdm(enumerate(data[label])):\n",
    "        tmp = ' '.join(del_filter1.findall(item))\n",
    "        tmp = spacing(tmp)\n",
    "        tmp = repeat_normalize(tmp, num_repeats=2)\n",
    "        data.at[idx, label] = tmp\n",
    "\n",
    "# label = 텍스트가 있는 컬럼 이름\n",
    "def regex_specialChar(data, label):\n",
    "    for idx, item in tqdm(enumerate(data[label])):\n",
    "        tmp = ' '.join(del_filter2.findall(item))\n",
    "        data.at[idx, label] = tmp\n",
    "        \n",
    "def split_sentence(data):\n",
    "    arr = []\n",
    "    for sentence in data:\n",
    "        for s in kss.split_sentences(sentence):\n",
    "            arr.append(s)\n",
    "    return arr\n",
    "\n",
    "# TextCol = 리뷰 텍스트가 있는 컬럼 이름\n",
    "# labelCol = 라벨링 되어있는 컬럼 이름\n",
    "def neg_pos_split(data, TextCol, labelCol):\n",
    "    neg = data[data[labelCol] == 0][TextCol]\n",
    "    pos = data[data[labelCol] == 1][TextCol]\n",
    "\n",
    "    neg = pd.DataFrame({TextCol: split_sentence(neg)})\n",
    "    pos = pd.DataFrame({TextCol: split_sentence(pos)})\n",
    "\n",
    "    neg[labelCol] = 0\n",
    "    pos[labelCol] = 1\n",
    "\n",
    "    # del record that have only 1 word\n",
    "    review_splited = pd.concat([pos, neg])\n",
    "    review_splited[\"len_text\"] = [len(t.split()) for t in review_splited[TextCol]]\n",
    "    review_splited_del_meaningless = review_splited[review_splited[\"len_text\"] > 1]\n",
    "    # flushing idx\n",
    "\n",
    "    review_splited_del_meaningless.index = [i for i in range(review_splited_del_meaningless[TextCol].size)]\n",
    "    review_splited_del_meaningless = review_splited_del_meaningless.drop(['len_text'], axis = 1)\n",
    "    return review_splited_del_meaningless\n",
    "\n",
    "def preprocessingPipeLine(data):\n",
    "    regex_spacing_normalization(data, 'text')\n",
    "    data = data.dropna(axis=0)\n",
    "    pre_data = neg_pos_split(data, 'text', 'label')\n",
    "    pre_data = pre_data.dropna(axis=0)\n",
    "    regex_specialChar(pre_data, 'text')\n",
    "    pre_data = pre_data.dropna(axis=0)\n",
    "    pre_data.drop_duplicates(subset=['text'], inplace=True)\n",
    "    return pre_data\n",
    "hotelData = pd.read_table('data/origin/hotel.txt')   \n",
    "movieData = pd.read_table('data/origin/movie.txt')    \n",
    "shoppingData = pd.read_table('data/origin/shopping.txt')     \n",
    "\n",
    "pre_movieData = preprocessingPipeLine(movieData) \n",
    "pre_shoppingData = preprocessingPipeLine(shoppingData)\n",
    "pre_hotelData = preprocessingPipeLine(hotelData) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = pd.read_table('data/origin/movie.txt')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25520</th>\n",
       "      <td>샘 킴 반지좀빼고요리하지 양손어다반지 비위생</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25521</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25522</th>\n",
       "      <td>진짜재밋어요!!! 또개봉했으면 좋겠다! 또봐야지</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25523</th>\n",
       "      <td>벌써 12년 이나 흘러버렸네.. 추억은 추억일때 아름다운 법.. 5년 이상 영화는 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25524</th>\n",
       "      <td>보기 전부터 스토리는 기대도 안했고, 선수라도 보는 재미를 원했건만...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146178</th>\n",
       "      <td>인간이 문제지.. 소는 뭔죄인가..</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146179</th>\n",
       "      <td>평점이 너무 낮아서...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146180</th>\n",
       "      <td>이게 뭐요? 한국인은 거들먹거리고 필리핀 혼혈은 착하다?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146181</th>\n",
       "      <td>청춘 영화의 최고봉.방황과 우울했던 날들의 자화상</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146182</th>\n",
       "      <td>한국 영화 최초로 수간하는 내용이 담긴 영화</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120663 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  label\n",
       "25520                            샘 킴 반지좀빼고요리하지 양손어다반지 비위생      0\n",
       "25521                                                 NaN      1\n",
       "25522                          진짜재밋어요!!! 또개봉했으면 좋겠다! 또봐야지      1\n",
       "25523   벌써 12년 이나 흘러버렸네.. 추억은 추억일때 아름다운 법.. 5년 이상 영화는 ...      0\n",
       "25524            보기 전부터 스토리는 기대도 안했고, 선수라도 보는 재미를 원했건만...      0\n",
       "...                                                   ...    ...\n",
       "146178                                인간이 문제지.. 소는 뭔죄인가..      0\n",
       "146179                                      평점이 너무 낮아서...      1\n",
       "146180                    이게 뭐요? 한국인은 거들먹거리고 필리핀 혼혈은 착하다?      0\n",
       "146181                        청춘 영화의 최고봉.방황과 우울했던 날들의 자화상      1\n",
       "146182                           한국 영화 최초로 수간하는 내용이 담긴 영화      0\n",
       "\n",
       "[120663 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt[25520:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import model_selection\n",
    "\n",
    "def hotel_data_split(data):\n",
    "    label = data[\"label\"]\n",
    "    hotel_train, hotel_test = sklearn.model_selection.train_test_split(data, test_size = 0.5, stratify=label)\n",
    "    return hotel_train, hotel_test\n",
    "\n",
    "def data_balancing_process(data, n):\n",
    "    label0_df = data.query('label==0').sample(n=n//2, random_state=2000)\n",
    "    label1_df = data.query('label==1').sample(n=n//2, random_state=2000)\n",
    "    dataTrain = pd.concat([label0_df, label1_df], ignore_index=True)\n",
    "    dataTrain = dataTrain.iloc[np.random.permutation(dataTrain.index)]\n",
    "    return dataTrain\n",
    "\n",
    "def data_concat2(hotelData, data, saveFileName):\n",
    "    trainData = pd.concat([hotelData, data], ignore_index=True)\n",
    "    trainData = trainData.iloc[np.random.permutation(trainData.index)]\n",
    "    trainData.to_csv(saveFileName, sep = '\\t', index = False)\n",
    "\n",
    "def data_concat3(hotelData, data1, data2, saveFileName):\n",
    "    trainData = pd.concat([hotelData, data1, data2], ignore_index=True)\n",
    "    trainData = trainData.iloc[np.random.permutation(trainData.index)]\n",
    "    trainData.to_csv(saveFileName, sep = '\\t', index = False)\n",
    "\n",
    "pre_hotel_train, pre_hotel_test = hotel_data_split(pre_hotelData)\n",
    "n = len(pre_hotel_train)\n",
    "\n",
    "pre_movieData = data_balancing_process(pre_movieData, n)\n",
    "pre_shoppingData = data_balancing_process(pre_shoppingData, n)\n",
    "\n",
    "pre_movieData.to_csv('data/preprocessing/movie.txt', sep = '\\t', index = False)\n",
    "pre_shoppingData.to_csv('data/preprocessing/shopping.txt', sep = '\\t', index = False)\n",
    "pre_hotel_train.to_csv('data/preprocessing/hotel_train.txt', sep = '\\t', index = False)\n",
    "pre_hotel_test.to_csv('data/preprocessing/hotel_test.txt', sep = '\\t', index = False)\n",
    "\n",
    "hotelData = pd.read_table('data/preprocessing/hotel_train.txt')   \n",
    "movieData = pd.read_table('data/preprocessing/movie.txt')    \n",
    "shoppingData = pd.read_table('data/preprocessing/shopping.txt')     \n",
    "\n",
    "\n",
    "data_concat2(hotelData, movieData, 'data/sentiment_test_dataset/hotel_movie_train.txt')\n",
    "data_concat2(hotelData, shoppingData, 'data/sentiment_test_dataset/hotel_shopping_train.txt')\n",
    "data_concat3(hotelData, movieData, shoppingData, 'data/sentiment_test_dataset/hotel_movie_shopping_train.txt')\n",
    "\n",
    "pre_hotel_train.to_csv('data/sentiment_test_dataset/hotel_train.txt', sep = '\\t', index = False)\n",
    "pre_hotel_test.to_csv('data/sentiment_test_dataset/hotel_test.txt', sep = '\\t', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>거실이 다른 숙소에 비해 넓은 편이라 강아지와 함께 지 내기 좋았어요</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>직원들끼리 소통이 전혀 없나 봅니다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>머리 둘레 59여서 사이즈 샀더니 딱 맞는 느낌으로 들어 맞습니다</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>새로 보내주신 이 제품마다 켜 지질 않네요</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>매우 청결하고 인테리어도 너무 예뻤어요</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103560</th>\n",
       "      <td>이불이 너무 무거웠다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103561</th>\n",
       "      <td>쌀씻을 용도로 샀는데 구멍 너무 커서 쌀 다 빠져나가요</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103562</th>\n",
       "      <td>체크인 응대는 좀 더 친절했으면 합니다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103563</th>\n",
       "      <td>호텔 생각보다 시설이나 환경면에서는 많이 아쉬웠습니다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103564</th>\n",
       "      <td>싸게 샀네요</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103565 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          text  label\n",
       "0       거실이 다른 숙소에 비해 넓은 편이라 강아지와 함께 지 내기 좋았어요      1\n",
       "1                          직원들끼리 소통이 전혀 없나 봅니다      0\n",
       "2         머리 둘레 59여서 사이즈 샀더니 딱 맞는 느낌으로 들어 맞습니다      1\n",
       "3                      새로 보내주신 이 제품마다 켜 지질 않네요      0\n",
       "4                        매우 청결하고 인테리어도 너무 예뻤어요      1\n",
       "...                                        ...    ...\n",
       "103560                             이불이 너무 무거웠다      0\n",
       "103561          쌀씻을 용도로 샀는데 구멍 너무 커서 쌀 다 빠져나가요      0\n",
       "103562                   체크인 응대는 좀 더 친절했으면 합니다      0\n",
       "103563           호텔 생각보다 시설이나 환경면에서는 많이 아쉬웠습니다      0\n",
       "103564                                  싸게 샀네요      1\n",
       "\n",
       "[103565 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1= pd.read_table('data/sentiment_test_dataset/hotel_shopping_train.txt')   \n",
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'end'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-110-e2fc3ace7931>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'end'"
     ]
    }
   ],
   "source": [
    "\n",
    "def data_concat_hotel_movie_train(naverTrainData, hotelTrainData):\n",
    "    nTrain = pd.read_table(naverTrainData)\n",
    "    hTrain = pd.read_csv(\"0.5hotel_train.csv\")\n",
    "    \n",
    "    movie0_df = aa.query('label==0').sample(n=26255, random_state=2000)\n",
    "    movie1_df = aa.query('label==1').sample(n=26255, random_state=2000)\n",
    "    \n",
    "    movieTrain = pd.concat([movie0_df, movie1_df], ignore_index=True)\n",
    "    \n",
    "    hTrain = hTrain.drop(['len_text'], axis=1)\n",
    "    hTrain['id'] = 1\n",
    "    hTrain = hTrain[['id', 'Text', 'Label']]\n",
    "    hTrain.columns = ['id','document','label']\n",
    "    #hTrain = hTrain.iloc[np.random.permutation(hTrain.index)].reset_index(drop=True)\n",
    "    \n",
    "    trainData = pd.concat([movieTrain, hTrain], ignore_index=True)\n",
    "    trainData = trainData.iloc[np.random.permutation(trainData.index)]\n",
    "    trainData.to_csv('sampleTrain.txt', sep = '\\t', index = False)\n",
    "\n",
    "def data_concat_hotel_movie_train(naverTrainData, hotelTrainData):\n",
    "    nTrain = pd.read_table(naverTrainData)\n",
    "    hTrain = pd.read_csv(hotelTrainData)\n",
    "    \n",
    "    movie0_df = aa.query('label==0').sample(n=26255, random_state=2000)\n",
    "    movie1_df = aa.query('label==1').sample(n=26255, random_state=2000)\n",
    "    \n",
    "    movieTrain = pd.concat([movie0_df, movie1_df], ignore_index=True)\n",
    "    \n",
    "    hTrain = hTrain.drop(['len_text'], axis=1)\n",
    "    hTrain['id'] = 1\n",
    "    hTrain = hTrain[['id', 'Text', 'Label']]\n",
    "    hTrain.columns = ['id','document','label']\n",
    "    #hTrain = hTrain.iloc[np.random.permutation(hTrain.index)].reset_index(drop=True)\n",
    "    \n",
    "    trainData = pd.concat([movieTrain, hTrain], ignore_index=True)\n",
    "    trainData = trainData.iloc[np.random.permutation(trainData.index)]\n",
    "    trainData.to_csv('sampleTrain.txt', sep = '\\t', index = False)\n",
    "    \n",
    "def data_concat_hotel_movie_train(naverTrainData, hotelTrainData):\n",
    "    nTrain = pd.read_table(naverTrainData)\n",
    "    hTrain = pd.read_csv(hotelTrainData)\n",
    "    \n",
    "    movie0_df = aa.query('label==0').sample(n=26255, random_state=2000)\n",
    "    movie1_df = aa.query('label==1').sample(n=26255, random_state=2000)\n",
    "    \n",
    "    movieTrain = pd.concat([movie0_df, movie1_df], ignore_index=True)\n",
    "    \n",
    "    hTrain = hTrain.drop(['len_text'], axis=1)\n",
    "    hTrain['id'] = 1\n",
    "    hTrain = hTrain[['id', 'Text', 'Label']]\n",
    "    hTrain.columns = ['id','document','label']\n",
    "    #hTrain = hTrain.iloc[np.random.permutation(hTrain.index)].reset_index(drop=True)\n",
    "    \n",
    "    trainData = pd.concat([movieTrain, hTrain], ignore_index=True)\n",
    "    trainData = trainData.iloc[np.random.permutation(trainData.index)]\n",
    "    trainData.to_csv('sampleTrain.txt', sep = '\\t', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>직원 분들이 정말로 친절하십니다.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>외국인 친구를 데리고 갔는데 특히 아침 조식 때 직원분이 많이 도와주셔서 정말로 간...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>그리고 데스크에 계신 직원분들도 체크 아웃하고 짐도 맡겨주시고 정말로 친절하셨습니다.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>방은 깨끗하고 특히 화장실이 청결했어요.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>약간 작은 방이긴 하지만 위치도 명동역에서 분 거리라 좋았습니다.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>침대 매트리스는 좋았어요</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>아침식사도 좋구요</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>편의시설 가까움</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>위치가 좋다</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>화장실이 넓고 위치가 좋아요</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>지하철에서 가깝습니다</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>화장실 편리하고 좋았어요</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>소음,기타시설은 마음에 듬.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>화장실이 샤워실과 분리되어서 좋았고..베드가 두개라 좁아서 답답함만 빼면 깨끗하고 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>지하철 역 과 가까웠고, 주변이 번화가였으나 씨끄럽지 않았고, 욕조가 있어서 좋았다</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>옆방 소음이 커서 잠을 못이뤘음</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>위치가 너무 좋아요!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>지하철역과도 가깝고 교통이 편리해요</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>가장좋은 점은 역시 주차문제를 해결할수 있다는거와 강남역 앞이라서 놀거리 먹거리 풍...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>침대도 편하고 불도 잘 들어왔고 바로 옆에 유명한 빵집이 있어서 좋았습니다.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>강남역 접근성은 좋음.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>위치는 좋았음 그거 말고는 잘 모르겠음</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>위치와 친절 함, 쇼핑몰 근처</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>방 바닥? 이 엄청 따뜻해요</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>그리고 직원분 칠절합니다</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>조식이 잘 나옴 호선 몽촌토성역에서 찾아갈 것 생각하면 위치 나쁘지 않음 먹자골목에...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>위치도 좋고, 주위에 편의점 등 시설이용이 쉬워서 좋았음.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>비싸기만한 조식뷔페보다 좋았던 조식의 구성, 쾌적한 룸. 티비에 넷플릭스랑 유튜브 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>거의 일 동안 잠만 잤기에 크게 불편한점은 없었음. 호텔과 모텔 딱 그 중간 수준 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>솔직히 잠만 자면 되었기에 룸 컨디션을 따지지 않았는데 가격대비 손해보는거 없이 적...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>쿠션같은거에 뭔가 찝찝한 흔적이 있었지만 침구 그 자체는 흰색으로 깔끔하게 유지 되...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>일 잤지만 침구가 변함없이 정말 청결해서 기분이 좋았습니다.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>저는 그 부분에 깐깐한편이데 침구가 깔끔해서 만족입니다.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>또한 발렛서비스가 되고 출차할때도 기분 좋게 나갈수 있도록 누르니 잘 준비해주셔서 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>직원들이 친절했고 가격에 비해 위치나 청결이 괜찮았음 넷플릭스가 나오고 근처에 석촌...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>직원분들 친절하고, 스파욕조도 좋았어요.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>거격대비 아주 좋았습니다.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>다른사람에게도 꼭 추천 해주고 싶더라구요</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>덕분에 편한한 잠자리가 되었습니다.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>식사구성이 굉장히 좋네요</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>맛집 거리 안에 위치한 숙소들 중에 외관부터 다른 숙소보다 신경쓴 것이 느껴지고 내...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>유튜브 보며 놀기도 좋고 노래방 하루 곡도 알짜 재미였어요.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>롯데월드나 아쿠아리움 가는 길에 석촌호수 지나갈 수 있어 좋아요.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>생각 외로 가성비가 좋았고 조식도 예쁘게 플레이팅 되어 나왔어요</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>방음만 괜찮다면 재방문 의사 있어용</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>병원땜에 묵었는데 편안하고 생각보다 깔끔 하긴했습니다.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>병원가기 좋은 위치인 듯 특히 아산병원 천호 미즈여성병원등등</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>위치가 좋고 아침에 정성가득한 조식이 좋았습니다.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>무료셔틀과 웰컴 드링크 서비스가 좋았어요</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>직원들 모두 친절하게 응대해주셔서 너무 좋았습니다</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Text  Label\n",
       "0                                  직원 분들이 정말로 친절하십니다.      1\n",
       "1   외국인 친구를 데리고 갔는데 특히 아침 조식 때 직원분이 많이 도와주셔서 정말로 간...      1\n",
       "2     그리고 데스크에 계신 직원분들도 체크 아웃하고 짐도 맡겨주시고 정말로 친절하셨습니다.      1\n",
       "3                              방은 깨끗하고 특히 화장실이 청결했어요.      1\n",
       "4                약간 작은 방이긴 하지만 위치도 명동역에서 분 거리라 좋았습니다.      1\n",
       "5                                       침대 매트리스는 좋았어요      1\n",
       "6                                           아침식사도 좋구요      1\n",
       "7                                            편의시설 가까움      1\n",
       "8                                              위치가 좋다      1\n",
       "9                                     화장실이 넓고 위치가 좋아요      1\n",
       "10                                        지하철에서 가깝습니다      1\n",
       "11                                      화장실 편리하고 좋았어요      1\n",
       "12                                    소음,기타시설은 마음에 듬.      1\n",
       "13  화장실이 샤워실과 분리되어서 좋았고..베드가 두개라 좁아서 답답함만 빼면 깨끗하고 ...      1\n",
       "14     지하철 역 과 가까웠고, 주변이 번화가였으나 씨끄럽지 않았고, 욕조가 있어서 좋았다      1\n",
       "15                                  옆방 소음이 커서 잠을 못이뤘음      1\n",
       "16                                        위치가 너무 좋아요!      1\n",
       "17                                지하철역과도 가깝고 교통이 편리해요      1\n",
       "18  가장좋은 점은 역시 주차문제를 해결할수 있다는거와 강남역 앞이라서 놀거리 먹거리 풍...      1\n",
       "19         침대도 편하고 불도 잘 들어왔고 바로 옆에 유명한 빵집이 있어서 좋았습니다.      1\n",
       "20                                       강남역 접근성은 좋음.      1\n",
       "21                              위치는 좋았음 그거 말고는 잘 모르겠음      1\n",
       "22                                   위치와 친절 함, 쇼핑몰 근처      1\n",
       "23                                    방 바닥? 이 엄청 따뜻해요      1\n",
       "24                                      그리고 직원분 칠절합니다      1\n",
       "25  조식이 잘 나옴 호선 몽촌토성역에서 찾아갈 것 생각하면 위치 나쁘지 않음 먹자골목에...      1\n",
       "26                   위치도 좋고, 주위에 편의점 등 시설이용이 쉬워서 좋았음.      1\n",
       "27  비싸기만한 조식뷔페보다 좋았던 조식의 구성, 쾌적한 룸. 티비에 넷플릭스랑 유튜브 ...      1\n",
       "28  거의 일 동안 잠만 잤기에 크게 불편한점은 없었음. 호텔과 모텔 딱 그 중간 수준 ...      1\n",
       "29  솔직히 잠만 자면 되었기에 룸 컨디션을 따지지 않았는데 가격대비 손해보는거 없이 적...      1\n",
       "30  쿠션같은거에 뭔가 찝찝한 흔적이 있었지만 침구 그 자체는 흰색으로 깔끔하게 유지 되...      1\n",
       "31                  일 잤지만 침구가 변함없이 정말 청결해서 기분이 좋았습니다.      1\n",
       "32                    저는 그 부분에 깐깐한편이데 침구가 깔끔해서 만족입니다.      1\n",
       "33  또한 발렛서비스가 되고 출차할때도 기분 좋게 나갈수 있도록 누르니 잘 준비해주셔서 ...      1\n",
       "34  직원들이 친절했고 가격에 비해 위치나 청결이 괜찮았음 넷플릭스가 나오고 근처에 석촌...      1\n",
       "35                             직원분들 친절하고, 스파욕조도 좋았어요.      1\n",
       "36                                     거격대비 아주 좋았습니다.      1\n",
       "37                             다른사람에게도 꼭 추천 해주고 싶더라구요      1\n",
       "38                                덕분에 편한한 잠자리가 되었습니다.      1\n",
       "39                                      식사구성이 굉장히 좋네요      1\n",
       "40  맛집 거리 안에 위치한 숙소들 중에 외관부터 다른 숙소보다 신경쓴 것이 느껴지고 내...      1\n",
       "41                  유튜브 보며 놀기도 좋고 노래방 하루 곡도 알짜 재미였어요.      1\n",
       "42               롯데월드나 아쿠아리움 가는 길에 석촌호수 지나갈 수 있어 좋아요.      1\n",
       "43                생각 외로 가성비가 좋았고 조식도 예쁘게 플레이팅 되어 나왔어요      1\n",
       "44                                방음만 괜찮다면 재방문 의사 있어용      1\n",
       "45                     병원땜에 묵었는데 편안하고 생각보다 깔끔 하긴했습니다.      1\n",
       "46                  병원가기 좋은 위치인 듯 특히 아산병원 천호 미즈여성병원등등      1\n",
       "47                        위치가 좋고 아침에 정성가득한 조식이 좋았습니다.      1\n",
       "48                             무료셔틀과 웰컴 드링크 서비스가 좋았어요      1\n",
       "49                        직원들 모두 친절하게 응대해주셔서 너무 좋았습니다      1"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_data.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'아아 ㅋㅋ'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repeat_normalize(\"아아아아아아 ㅋㅋㅋㅋㅋㅋ\", num_repeats=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neg, pos division\n",
    "neg = review_df[review_df[\"Label\"] == 0][\"Text\"]\n",
    "pos = review_df[review_df[\"Label\"] == 1][\"Text\"]\n",
    "\n",
    "def split_sentence(texts_df):\n",
    "    arr = []\n",
    "    for sentence in tqdm(texts_df):\n",
    "        for s in kss.split_sentences(sentence):\n",
    "            arr.append(s)\n",
    "    return arr\n",
    "\n",
    "\n",
    "neg = pd.DataFrame({\"Text\": split_sentence(neg)})\n",
    "pos = pd.DataFrame({\"Text\": split_sentence(pos)})\n",
    "\n",
    "neg[\"Label\"] = 0\n",
    "pos[\"Label\"] = 1\n",
    "\n",
    "# del record that have only 1 word\n",
    "\n",
    "review_splited = pd.concat([pos, neg])\n",
    "review_splited[\"len_text\"] = [len(t.split()) for t in review_splited[\"Text\"]]\n",
    "review_splited_del_meaningless = review_splited[review_splited[\"len_text\"] > 1]\n",
    "\n",
    "# flushing idx\n",
    "\n",
    "review_splited_del_meaningless.index = [i for i in range(review_splited_del_meaningless[\"Text\"].size)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
